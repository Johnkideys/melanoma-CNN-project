{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johnkideys/melanoma-CNN-project/blob/main/cnn_models_for_melanoma_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9_xiLNcQn8q",
        "outputId": "70738000-70b7-4ccd-b4ac-d6e893e4ce90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Code to connect to my google drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# mount google drive to google colab session\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KnALoEZbs-qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet - Configuration 4"
      ],
      "metadata": {
        "id": "txaG9AJRs50i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "# paths to data\n",
        "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Data_oversampled\"\n",
        "val_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Validation_Data\"\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Draft\"\n",
        "\n",
        "\n",
        "# initial parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# creating funvtions to load dataset and apply data augmenttaion\n",
        "def augment_data(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    return image, label\n",
        "\n",
        "def load_dataset(directory, batch_size=BATCH_SIZE, img_size=IMG_SIZE, shuffle=True, augment=False):\n",
        "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    if augment: # can choose to augment or not when loading the daatset\n",
        "        dataset = dataset.map(augment_data)\n",
        "\n",
        "    return dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Datasets are created here for train and validation\n",
        "train_dataset = load_dataset(train_data_dir, augment=True)\n",
        "val_dataset = load_dataset(val_data_dir, shuffle=False)\n",
        "\n",
        "# ResNet50 model initialisation\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "base_model.trainable = False  # freezing the model first, fine tuning later\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# class weights created, I will assign 3 and 1\n",
        "class_weight = {0: 3.0, 1: 1.0}\n",
        "# Higher weight for melanoma class\n",
        "\n",
        "# Compiling the model with weighted loss\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training stage below\n",
        "callbacks = [\n",
        "    ModelCheckpoint(os.path.join(checkpoint_dir, \"resnet_isic_2017_ver4.h5\"), save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_dataset,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "## FINE-TUNING (Unfreeze Some ResNet50 Layers)\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:  # Keep first 100 layers frozen # So last 75 layers are fine tuned\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),  # Lower learning rate for fine-tuning is better\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Fine-tune applied\n",
        "fine_tune_epochs = 10\n",
        "history_fine = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=fine_tune_epochs,\n",
        "    validation_data=val_dataset,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "### Evaluation of the model\n",
        "y_true = []\n",
        "for _, labels in val_dataset:\n",
        "    y_true.append(labels.numpy())\n",
        "y_true = np.concatenate(y_true)\n",
        "\n",
        "y_pred_probs = model.predict(val_dataset)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "melanoma_f1 = f1_score(y_true, y_pred, pos_label=0)\n",
        "melanoma_precision = precision_score(y_true, y_pred, pos_label=0)\n",
        "melanoma_recall = recall_score(y_true, y_pred, pos_label=0)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Final Validation Metrics (Melanoma - Class 0):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score - (Melanoma): {melanoma_f1:.4f}\")\n",
        "print(f\"Precision - (Melanoma): {melanoma_precision:.4f}\")\n",
        "print(f\"Recall (Melanoma): {melanoma_recall:.4f}\")\n",
        "\n",
        "# Plot charts to understand behaviour as epochs progress\n",
        "def plot_training_history(history, title=\"Model Training\"):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'{title} - Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'{title} - Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history, title=\"Initial Training\")\n",
        "plot_training_history(history_fine, title=\"Fine-Tuning\")\n",
        "\n",
        "# Classification report printed\n",
        "print(\"Classification Report (Melanoma Focused):\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Melanoma', 'Non-Melanoma']))\n"
      ],
      "metadata": {
        "id": "vR5zhCirsoO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In this cell I load the test data and use it on the trained model\n",
        "# Path to test data on my drive\n",
        "test_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Test_Sorted_Data\"\n",
        "\n",
        "# Load the test dataset - no augmentation is used for test set\n",
        "test_dataset = load_dataset(test_data_dir, augment=False, shuffle=False)\n",
        "\n",
        "# evaluation of model on test set\n",
        "y_true_test = []\n",
        "for _, labels in test_dataset:\n",
        "    y_true_test.append(labels.numpy())\n",
        "y_true_test = np.concatenate(y_true_test)\n",
        "\n",
        "# Predict the test dataset\n",
        "y_pred_probs_test = model.predict(test_dataset)\n",
        "y_pred_test = (y_pred_probs_test > 0.5).astype(int)\n",
        "\n",
        "# Getting performance metrics for the test set\n",
        "test_melanoma_f1 = f1_score(y_true_test, y_pred_test, pos_label=0)\n",
        "test_melanoma_precision = precision_score(y_true_test, y_pred_test, pos_label=0)\n",
        "test_melanoma_recall = recall_score(y_true_test, y_pred_test, pos_label=0)\n",
        "test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
        "\n",
        "print(f\"\\nTest Set Metrics (Melanoma - Class 0):\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"F1 Score (Melanoma): {test_melanoma_f1:.4f}\")\n",
        "print(f\"Precision (Melanoma): {test_melanoma_precision:.4f}\")\n",
        "print(f\"Recall (Melanoma): {test_melanoma_recall:.4f}\")\n",
        "\n",
        "# Classification report provided\n",
        "print(\"\\nClassification Report on Test Set (Melanoma Focused):\")\n",
        "print(classification_report(y_true_test, y_pred_test, target_names=['Melanoma', 'Non-Melanoma']))\n"
      ],
      "metadata": {
        "id": "8SarTIT9soM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet - Configuration 6"
      ],
      "metadata": {
        "id": "qRNpbv3ntFjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = (128, 128)  # Resize all of the images to this(square size)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# Setting random seeds for reproducibility purposes\n",
        "import random\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Paths to datasets on my google drive\n",
        "training_data_path = '/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Data'\n",
        "validation_data_path = '/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Validation_Data'\n",
        "\n",
        "# Preparing Data Generators (slower method, initially used)\n",
        "train_datagen = ImageDataGenerator(\n",
        "   rescale=1./255,  # Normalise pixel values\n",
        "   rotation_range=30,\n",
        "   width_shift_range=0.2,\n",
        "   height_shift_range=0.2,\n",
        "   shear_range=0.2,\n",
        "   zoom_range=0.2,\n",
        "   horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "   rescale=1./255  # I am only normalising validation data, no augmentation\n",
        ")\n",
        "\n",
        "# Training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "   training_data_path,\n",
        "   target_size=IMG_SIZE,\n",
        "   batch_size=BATCH_SIZE,\n",
        "   class_mode='binary'\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "   validation_data_path,\n",
        "   target_size=IMG_SIZE,\n",
        "   batch_size=BATCH_SIZE,\n",
        "   class_mode='binary'\n",
        ")\n",
        "\n",
        "# Getting balanced class weights\n",
        "class_weights = compute_class_weight(\n",
        "   class_weight='balanced',\n",
        "   classes=np.unique(train_generator.classes),\n",
        "   y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# ResNet Model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers to keep pretrained weights\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom classification layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Replace Flatten with GlobalAveragePooling\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Regularisation of 0.5 for dropout\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# model created below\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "             loss='binary_crossentropy',  # For binary classification\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "## Train the model, takes time cause of ImageDataGenerator probably\n",
        "history = model.fit(\n",
        "   train_generator,\n",
        "   epochs=EPOCHS,\n",
        "   validation_data=val_generator,\n",
        "   class_weight=class_weights\n",
        ")\n",
        "\n",
        "## Saving model to new directory on drive\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Main/isic_resnet_model_ver6.h5')\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {loss}\")\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot charts over epochs\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot charts for  loss over epochs\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# other metrics\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = val_generator.classes\n",
        "y_pred = (model.predict(val_generator) > 0.5).astype(\"int32\")\n",
        "print(classification_report(y_true, y_pred, target_names=val_generator.class_indices.keys()))"
      ],
      "metadata": {
        "id": "YqH617CFtCxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Loading the saved model to use on test set\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Main/isic_resnet_model_ver6.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Test data path\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Test_Sorted_Data'\n",
        "\n",
        "# Getting test data generator ready\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "   test_data_path,\n",
        "   target_size=(128, 128),\n",
        "   batch_size=32,\n",
        "   class_mode='binary',\n",
        "   shuffle=False\n",
        ")\n",
        "\n",
        "# Predictions..\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Classification report given\n",
        "print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "Y6s8eb-2soI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet"
      ],
      "metadata": {
        "id": "aTlgGdjqtdAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#\n",
        "# To get same results every time I run it, using \"random\" library\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# issues connecxting to drive so pasted code again here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# directories in drive\n",
        "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Data\"\n",
        "val_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Validation_Data\"\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Main\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# initial parameters given\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Function to augment images created as was confusing before if needed\n",
        "def augment_image(image, label):\n",
        "    \"\"\"augmentation function\"\"\"\n",
        "    # Random transformations part\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    # Random rotation part\n",
        "    angle = tf.random.uniform([], -0.52, 0.52)  # -30 to 30 degrees\n",
        "    image = tf.image.rot90(image, k=tf.cast(angle/(np.pi/2), tf.int32) % 4)\n",
        "    # Random zoom and crop part\n",
        "    image = tf.image.central_crop(image, central_fraction=0.8)\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "\n",
        "    return tf.clip_by_value(image, 0.0, 1.0), label\n",
        "\n",
        "# Load the dataset\n",
        "def create_dataset(data_dir, batch_size, shuffle=True, augment=False):\n",
        "    \"\"\"Create tf.data.Dataset from the directory\"\"\"\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=shuffle,\n",
        "        seed=SEED\n",
        "    )\n",
        "\n",
        "    # Normalise and will try augment and without\n",
        "    dataset = dataset.map(lambda x, y: (x/255.0, y))\n",
        "    if augment:\n",
        "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Creating the  datasets\n",
        "train_dataset = create_dataset(train_data_dir, BATCH_SIZE, shuffle=True, augment=True)\n",
        "val_dataset = create_dataset(val_data_dir, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Class weights creation using balanced\n",
        "labels = np.concatenate([y.numpy() for x, y in train_dataset], axis=0).flatten()\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# F1 score\n",
        "\"\"\"\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.precision.reset_state()\n",
        "        self.recall.reset_state()\n",
        "\"\"\"\n",
        "\n",
        "# DenseNet201 model initialised\n",
        "base_model = DenseNet201(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(*IMG_SIZE, 3)\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(*IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', F1Score(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "# Callbacks for the model\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        os.path.join(checkpoint_dir, 'best_model.h5'),\n",
        "        monitor='val_f1_score',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_f1_score',\n",
        "        patience=5,\n",
        "        mode='max',\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_f1_score',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"Starting initial training...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_dataset,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "# This section is for fine-tuning\n",
        "print(\"\\nUnfreezing layers for fine-tuning...\")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', F1Score(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "print(\"\\nStarting fine-tuning...\")\n",
        "history_fine = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS//2,\n",
        "    initial_epoch=history.epoch[-1],\n",
        "    validation_data=val_dataset,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation of the model\n",
        "def evaluate_model(dataset, name):\n",
        "    y_true = np.concatenate([y.numpy() for x, y in dataset], axis=0).flatten()\n",
        "    y_pred = (model.predict(dataset) > 0.5).astype(int)\n",
        "\n",
        "    print(f\"\\n{name} Set Evaluation:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=['Non-Melanoma', 'Melanoma']))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(f\"\\nF1 Score: {f1_score(y_true, y_pred):.4f}\")\n",
        "\n",
        "evaluate_model(train_dataset, \"Training\")\n",
        "evaluate_model(val_dataset, \"Validation\")\n",
        "\n",
        "# Saved final model to checkpoints directory in drive\n",
        "final_model_path = os.path.join(checkpoint_dir, 'densenet_model_ver1.h5')\n",
        "model.save(final_model_path)\n",
        "print(f\"\\nFinal model saved to: {final_model_path}\")"
      ],
      "metadata": {
        "id": "QVWlEm05tbAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell to use saved densenet model on test set of ISIC 2017 sorted\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# paths to test set\n",
        "test_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Test_Sorted_Data\"\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "SEED = 42\n",
        "\n",
        "# loading the model saved\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Main/densenet_model_ver1.h5\"\n",
        "model = tf.keras.models.load_model(\n",
        "    model_path,\n",
        "    custom_objects={\n",
        "        'F1Score': F1Score\n",
        "    }\n",
        ")\n",
        "\n",
        "# function to get the test set\n",
        "def create_test_dataset(data_dir, batch_size):\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=False,\n",
        "        seed=SEED\n",
        "    )\n",
        "    dataset = dataset.map(lambda x, y: (x / 255.0, y))  # Normalsi\n",
        "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = create_test_dataset(test_data_dir, BATCH_SIZE)\n",
        "\n",
        "# Evaluate model and print metrics\n",
        "y_true = np.concatenate([y.numpy() for x, y in test_dataset], axis=0).flatten()\n",
        "y_pred_probs = model.predict(test_dataset)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"Test Set Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Non-Melanoma', 'Melanoma']))\n",
        "print(\"\\n Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(f\"\\nF1 Score: {f1_score(y_true, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "H7ePMNtntmMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNetV2 - Configuration 2\n"
      ],
      "metadata": {
        "id": "8xRb6RrcuCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "# paths to data\n",
        "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Data\"\n",
        "val_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Validation_Data\"\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Main\"\n",
        "\n",
        "# initial parameters, 96 96 for speeding up training\n",
        "IMG_SIZE = (96, 96)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 15\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Setting random seeds for reproducibility purposes\n",
        "import random\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Data generators created and images normalised\n",
        "datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# For Class Imbalance we use class weights\n",
        "labels = train_generator.classes  # Get labels\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(f\"Class Weights: {class_weights}\")\n",
        "\n",
        "# MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "base_model.trainable = False  # Freeze the base model initially\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)  # Sigmoid activation used for binary classification\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# callbacks created including early stopping\n",
        "callbacks = [\n",
        "    ModelCheckpoint(os.path.join(checkpoint_dir, \"mobilenet_isic_2017_ver2.h5\"), save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    class_weight=class_weights,  # Apply class weights\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Fine Tuning section\n",
        "print(\"\\nFine-tuning top layers of MobileNetV2...\")\n",
        "\n",
        "# Unfreeze last few layers for fine-tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-30]:  # Keep most of the layers frozen\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with a lower learning rate for fine-tuning\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE / 10),  #\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine_tune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS // 2,  # Less epochs for fine-tuning\n",
        "    validation_data=val_generator,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "y_true = val_generator.classes  # real labels of data\n",
        "y_pred_probs = model.predict(val_generator)  # Predicted probabilities\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)  # Convert to binary predictions\n",
        "\n",
        "# Compute metrics\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "\n",
        "print(f\"\\nFinal Validation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Non-Melanoma', 'Melanoma']))\n"
      ],
      "metadata": {
        "id": "WNnwdIPluH2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(classification_report(y_true, y_pred, target_names=['Non-Melanoma', 'Melanoma']))\n",
        "# Checked below for data quality\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Data\"\n",
        "val_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Validation_Data\"\n",
        "\n",
        "# Function to count images in subfolders\n",
        "def count_images(directory):\n",
        "    counts = {}\n",
        "    for subfolder in os.listdir(directory):\n",
        "        subfolder_path = os.path.join(directory, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            counts[subfolder] = len(os.listdir(subfolder_path))\n",
        "    return counts\n",
        "\n",
        "# Get counts for train and validation datasets\n",
        "train_counts = count_images(train_data_dir)\n",
        "val_counts = count_images(val_data_dir)\n",
        "print(\"\\nTraining Data numbers:\")\n",
        "for category, count in train_counts.items():\n",
        "    print(f\"{category}: {count} images\")\n",
        "\n",
        "print(\"\\nValidation Data numbers:\")\n",
        "for category, count in val_counts.items():\n",
        "    print(f\"{category}: {count} images\")\n"
      ],
      "metadata": {
        "id": "I_HgYnMZuHzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the trained model on the test set\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "# loading model with parameters\n",
        "test_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Test_Sorted_Data\"\n",
        "IMG_SIZE = (96, 96)\n",
        "BATCH_SIZE = 16\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Main/mobilenet_isic_2017_ver2.h5\"\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Getting the predicitions\n",
        "y_true = test_generator.classes\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Computing operformance metrics\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"\\nTest Set Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Classification report:\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))\n"
      ],
      "metadata": {
        "id": "Fi8X7TEhuOJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNetV2 - Configuration 3.1"
      ],
      "metadata": {
        "id": "mPeP7Agqt0ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "# paths to data\n",
        "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Data\"\n",
        "val_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Validation_Data\"\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints\"\n",
        "\n",
        "# initial parameters, using 224 224 for more detail\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "\n",
        "# Data Augmentation steps applied\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale=1.0 / 255.0).flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Class weights using balanced\n",
        "labels = train_generator.classes\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(f\"Class Weights: {class_weights}\")\n",
        "\n",
        "# Focal loss function created for class imbalance\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -K.mean(alpha * K.pow(1 - pt, gamma) * K.log(pt))\n",
        "    return loss\n",
        "\n",
        "# MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "base_model.trainable = False  # Freeze the base model initially\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)  # Sigmoid for the binary classification\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile model but with focal loss\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=focal_loss(alpha=0.25, gamma=2.0),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "C#allbacks listed\n",
        "callbacks = [\n",
        "    ModelCheckpoint(os.path.join(checkpoint_dir, \"mobilenet_isic_2017.h5\"), save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Fine-tuning the model\n",
        "print(\"\\nFine-tuning deeper layers of MobileNetV2...\")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss=focal_loss(alpha=0.25, gamma=2.0),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine_tune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS // 2,\n",
        "    validation_data=val_generator,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluation of model\n",
        "y_true = val_generator.classes\n",
        "y_pred_probs = model.predict(val_generator)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "\n",
        "print(f\"\\nFinal Validation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Melanoma', 'Non-Melanoma']))\n",
        "\n",
        "# Training charts plotted\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot initial training history\n",
        "plot_history(history)\n",
        "\n",
        "# Plot fine-tuning history\n",
        "plot_history(history_fine_tune)\n"
      ],
      "metadata": {
        "id": "ywiUKA8ctz2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for predictions on test set\n",
        "# Loading test set from drive\n",
        "test_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Test_Sorted_Data\"\n",
        "\n",
        "test_dataset = create_dataset(test_data_dir, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Evaluation and printing of metrics\n",
        "y_test_true = np.concatenate([y.numpy() for _, y in test_dataset], axis=0)\n",
        "y_test_probs = model.predict(test_dataset)\n",
        "y_test_pred = (y_test_probs > 0.5).astype(int)\n",
        "\n",
        "test_f1 = f1_score(y_test_true, y_test_pred)\n",
        "test_precision = precision_score(y_test_true, y_test_pred)\n",
        "test_recall = recall_score(y_test_true, y_test_pred)\n",
        "test_accuracy = np.mean(y_test_true == y_test_pred)\n",
        "\n",
        "print(f\"\\nTest Metrics:\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_report(y_test_true, y_test_pred, target_names=['Melanoma', 'Non-Melanoma']))\n"
      ],
      "metadata": {
        "id": "0OlfRyBmt_wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNetV2 - Configuration 5"
      ],
      "metadata": {
        "id": "tNqbKvpXsb46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "# Mount Google Drive in this cell for ease\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set random seeds for reproducibility purposes\n",
        "import random\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "\n",
        "# paths to data\n",
        "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Data\"\n",
        "val_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Sorted_Validation_Data\"\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Checkpoints/Main\"\n",
        "\n",
        "# initial parameters, using 224 224 for more detail\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "\n",
        "\n",
        "# function to apply data augmentation\n",
        "def augment_image(image, label):\n",
        "    \"\"\"\n",
        "    This function applies data augmentation to an image from the dataset.\n",
        "    \"\"\"\n",
        "    # horizontal flip\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    # Random rotation\n",
        "    angle = tf.random.uniform([], -0.52, 0.52)  # -30 to 30 degrees in radians\n",
        "    image = tf.image.rot90(image, k=tf.cast(angle / (np.pi / 2), tf.int32) % 4)\n",
        "    # Random brightness adjustments\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    # Random contrast adjustment\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    # Random zoom and crop\n",
        "    image = tf.image.central_crop(image, central_fraction=0.8)\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "# Loading dataset\n",
        "def create_dataset(data_dir, batch_size, shuffle=True, augment=False):\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset from a directory of images.\n",
        "    \"\"\"\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    # Normalise images to between 0 and 1\n",
        "    dataset = dataset.map(lambda x, y: (x / 255.0, y))\n",
        "\n",
        "    # Apply augmentation if needed\n",
        "    if augment:\n",
        "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # Prefetch for faster loading of images\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Create training dataset with the augmentation\n",
        "train_dataset = create_dataset(train_data_dir, BATCH_SIZE, shuffle=True, augment=True)\n",
        "# Create validation dataset without the augmentation\n",
        "val_dataset = create_dataset(val_data_dir, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# class weights created here\n",
        "labels = np.concatenate([y.numpy() for x, y in train_dataset], axis=0)\n",
        "labels = labels.flatten()  # Flatten the 2D array to 1D\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(f\"Class Weights: {class_weights}\")\n",
        "\n",
        "#Focal loss function\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -K.mean(alpha * K.pow(1 - pt, gamma) * K.log(pt))\n",
        "    return loss\n",
        "\n",
        "# MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "base_model.trainable = False  # Freeze the base model initially\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)  # Sigmoid for binary classification\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile model with the Focal Loss\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=focal_loss(alpha=0.25, gamma=2.0),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# callbacks listed\n",
        "callbacks = [\n",
        "    ModelCheckpoint(os.path.join(checkpoint_dir, \"mobilenet_isic_2017_ver5.h5\"), save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_dataset,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Fine-Tuning stage\n",
        "print(\"\\nFine-tuning deeper layers of MobileNetV2...\")\n",
        "\n",
        "# Unfreeze last 50 layers for fine-tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with a lower learning rate\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss=focal_loss(alpha=0.25, gamma=2.0),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine_tune = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS // 2,\n",
        "    validation_data=val_dataset,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluation and predictions\n",
        "y_true = np.concatenate([y.numpy() for x, y in val_dataset], axis=0)\n",
        "y_true = y_true.flatten()  # Flatten the 2D array to 1D\n",
        "y_pred_probs = model.predict(val_dataset)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Compute metrics\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "\n",
        "print(f\"\\nFinal Validation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nCorrected Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Melanoma', 'Non-Melanoma']))"
      ],
      "metadata": {
        "id": "KDcGtxMerpBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------Load Model from Checkpoint-----\n",
        "# Load the best model weights from the checkpoint\n",
        "best_model_path = os.path.join(checkpoint_dir, \"mobilenet_isic_2017_ver5.h5\")\n",
        "model.load_weights(best_model_path)\n",
        "#print(f\"Loaded best model weights from: {best_model_path}\")\n",
        "\n",
        "# Loading test data\n",
        "test_data_dir = \"/content/drive/MyDrive/Colab Notebooks/Keele - MSc project/Data/ISIC-2017_Test_Sorted_Data\"\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = create_dataset(test_data_dir, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Evaluation\n",
        "# Get true labels from the test dataset\n",
        "y_true_test = np.concatenate([y.numpy() for x, y in test_dataset], axis=0)\n",
        "y_true_test = y_true_test.flatten()  # Flattening to 1D array\n",
        "\n",
        "# predictions\n",
        "y_pred_probs_test = model.predict(test_dataset)\n",
        "\n",
        "# Convert probabilities to predictions using 0.5 as threshold\n",
        "y_pred_test = (y_pred_probs_test > 0.5).astype(int)\n",
        "\n",
        "# Compute metrics\n",
        "test_accuracy = np.mean(y_true_test == y_pred_test)\n",
        "test_f1 = f1_score(y_true_test, y_pred_test)\n",
        "test_precision = precision_score(y_true_test, y_pred_test)\n",
        "test_recall = recall_score(y_true_test, y_pred_test)\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "\n",
        "# Classification report for the test set given\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(y_true_test, y_pred_test, target_names=['Melanoma', 'Non-Melanoma']))"
      ],
      "metadata": {
        "id": "E58fYEUSro_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4CCh1rX_ro5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4LoXG2kAro3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "aTlgGdjqtdAJ"
      ],
      "authorship_tag": "ABX9TyM/uscOrvcUXQH+tZfStWlW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}